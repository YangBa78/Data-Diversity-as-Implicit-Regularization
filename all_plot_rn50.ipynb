{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_cf10 = 'cf10-rn/ww-df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_merge_layers(folder_path,suffix):\n",
    "    # Initialize dictionaries to store DataFrames for ft and non-ft files\n",
    "    dataframes_ft = {}\n",
    "    dataframes_non_ft = {}\n",
    "\n",
    "    # List all CSV files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    # Loop through each file and categorize it as 'ft' or 'non-ft'\n",
    "    for file in files:\n",
    "        # Check if file matches the ft pattern\n",
    "        if f'_{suffix}_ft.csv' in file:\n",
    "            base_name = file.replace(f'_{suffix}_ft.csv', '')\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            # Read the entire DataFrame from the ft file\n",
    "            df = pd.read_csv(file_path)\n",
    "            if not df.empty:\n",
    "                dataframes_ft[base_name] = df\n",
    "        # Check if file matches the non-ft pattern\n",
    "        elif f'_{suffix}.csv' in file:\n",
    "            base_name = file.replace(f'_{suffix}.csv', '')\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            # Read the entire DataFrame from the non-ft file\n",
    "            df = pd.read_csv(file_path)\n",
    "            if not df.empty:\n",
    "                dataframes_non_ft[base_name] = df\n",
    "\n",
    "    # Initialize a list to store the differences DataFrames\n",
    "    list_differences = []\n",
    "\n",
    "    # Compute the differences for each matching pair\n",
    "    for base_name in dataframes_ft:\n",
    "        if base_name in dataframes_non_ft:\n",
    "            df_ft = dataframes_ft[base_name]\n",
    "            df_non_ft = dataframes_non_ft[base_name]\n",
    "\n",
    "            # Align DataFrames on both axes (rows and columns)\n",
    "            df_ft_aligned, df_non_ft_aligned = df_ft.align(df_non_ft, join='outer', axis=None, fill_value=0)\n",
    "\n",
    "            # Convert boolean columns to integers\n",
    "            for df in [df_ft_aligned, df_non_ft_aligned]:\n",
    "                bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "                df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "            # Convert all columns to numeric, coercing errors to NaN\n",
    "            df_ft_numeric = df_ft_aligned.apply(pd.to_numeric, errors='coerce')\n",
    "            df_non_ft_numeric = df_non_ft_aligned.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Fill NaN values with 0 (optional, depending on how you want to handle missing values)\n",
    "            df_ft_numeric = df_ft_numeric.fillna(0)\n",
    "            df_non_ft_numeric = df_non_ft_numeric.fillna(0)\n",
    "\n",
    "            # Compute the difference between the ft and non-ft DataFrames\n",
    "            df_diff = df_ft_numeric - df_non_ft_numeric\n",
    "\n",
    "            # Add a column to identify the pair\n",
    "            df_diff['base_name'] = base_name\n",
    "            df_diff['layer_id'] = df_ft_numeric['layer_id']\n",
    "\n",
    "            # Optional: Reset index to ensure a proper stacking\n",
    "            df_diff.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Append to the list\n",
    "            list_differences.append(df_diff)\n",
    "\n",
    "    # Concatenate all the difference DataFrames\n",
    "    if list_differences:\n",
    "        df_all_differences = pd.concat(list_differences, ignore_index=True)\n",
    "    else:\n",
    "        df_all_differences = pd.DataFrame()  # Return empty DataFrame if no differences found\n",
    "\n",
    "    return df_all_differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_cf10 = delta_merge_layers(df_path_cf10, 'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_cf10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_cf10 = la_cf10[['layer_id', 'alpha',  'entropy', 'log_norm', 'log_spectral_norm', 'base_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_d_cf10 = la_cf10.drop(la_cf10[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']][(la_cf10[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']] == 0).all(axis=1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_differences(df):\n",
    "    \"\"\"\n",
    "    Computes pairwise differences between all categories and 'bs' based on 'base_name',\n",
    "    for matching 'layer_id's.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame containing 'base_name', 'layer_id', and numeric columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the differences with columns 'base_name', 'layer_id', and difference columns.\n",
    "    \"\"\"\n",
    "    # Identify numeric columns excluding 'layer_id'\n",
    "    numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "    if 'layer_id' in numeric_cols:\n",
    "        numeric_cols.remove('layer_id')\n",
    "\n",
    "    # Separate 'bs' and other categories\n",
    "    df_bs = df[df['base_name'] == 'bs']\n",
    "    df_others = df[df['base_name'] != 'bs']\n",
    "\n",
    "    # Merge on 'layer_id'\n",
    "    df_merged = pd.merge(\n",
    "        df_others,\n",
    "        df_bs,\n",
    "        on='layer_id',\n",
    "        suffixes=('', '_bs'),\n",
    "        how='inner'  # Ensure only matching 'layer_id's are joined\n",
    "    )\n",
    "\n",
    "    # Compute differences for numeric columns\n",
    "    for col in numeric_cols:\n",
    "        df_merged[f'{col}_diff'] = df_merged[col] - df_merged[f'{col}_bs']\n",
    "\n",
    "    # Prepare the final DataFrame\n",
    "    cols_to_keep = ['base_name', 'layer_id'] + [f'{col}_diff' for col in numeric_cols]\n",
    "    df_differences = df_merged[cols_to_keep]\n",
    "\n",
    "    # Reset index and sort (optional)\n",
    "    df_differences.reset_index(drop=True, inplace=True)\n",
    "    df_differences.sort_values(by=['base_name', 'layer_id'], inplace=True)\n",
    "\n",
    "    return df_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_dif_cf10 = compute_pairwise_differences(la_d_cf10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_index(index_value):\n",
    "    if 'div' in index_value:\n",
    "        return 'div'\n",
    "    elif 'dp' in index_value:\n",
    "        return 'dp'\n",
    "    elif 'wd' in index_value:\n",
    "        return 'wd'\n",
    "    else:\n",
    "        return 'bs'  # Optional: in case none of the patterns match\n",
    "\n",
    "# Apply the function to the index and create a new column\n",
    "la_dif_cf10['category'] = la_dif_cf10['base_name'].map(categorize_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_cf10 = la_dif_cf10.drop(['base_name'], axis=1).groupby(['layer_id', 'category'], as_index=False).mean()\n",
    "la_avg_cf10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_cf10.loc[la_avg_cf10['layer_id'] == 343, 'layer_id'] = 235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_cf10.groupby('category').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_cf100 = 'cf100-rn/ww-df'\n",
    "la_cf100 = delta_merge_layers(df_path_cf100, 'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_cf100 = la_cf100[['layer_id', 'alpha',  'entropy', 'log_norm', 'log_spectral_norm', 'base_name']]\n",
    "la_cf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_d_cf100 = la_cf100.drop(la_cf100[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']][(la_cf100[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']] == 0).all(axis=1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_dif_cf100 = compute_pairwise_differences(la_d_cf100)\n",
    "la_dif_cf100['category'] = la_dif_cf100['base_name'].map(categorize_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_cf100 = la_dif_cf100.drop(['base_name'], axis=1).groupby(['layer_id', 'category'], as_index=False).mean()\n",
    "la_avg_cf100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_cf100.loc[la_avg_cf100['layer_id'] == 343, 'layer_id'] = 235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_cf100.groupby('category').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_car = 'car_train/ww-df'\n",
    "la_car = delta_merge_layers(df_path_car, 'int')\n",
    "\n",
    "la_car = la_car[['layer_id', 'alpha',  'entropy', 'log_norm', 'log_spectral_norm', 'base_name']]\n",
    "la_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_d_car = la_car.drop(la_car[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']][(la_car[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']] == 0).all(axis=1)].index)\n",
    "\n",
    "la_dif_car = compute_pairwise_differences(la_d_car)\n",
    "la_dif_car['category'] = la_dif_car['base_name'].map(categorize_index)\n",
    "\n",
    "la_dif_car\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_car = la_dif_car.drop(['base_name'], axis=1).groupby(['layer_id', 'category'], as_index=False).mean()\n",
    "la_avg_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_car.loc[la_avg_car['layer_id'] == 343, 'layer_id'] = 235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_car.groupby('category').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_merge_layers_(folder_path):\n",
    "    # Initialize dictionaries to store DataFrames for ft and non-ft files\n",
    "    dataframes_ft = {}\n",
    "    dataframes_non_ft = {}\n",
    "\n",
    "    # List all CSV files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    # Loop through each file and categorize it as 'ft' or 'non-ft'\n",
    "    for file in files:\n",
    "        # Check if file matches the ft pattern\n",
    "        if file.startswith('ft_'):  # Identify \"ft\" files\n",
    "            base_name = file.replace('ft_', '').replace('.csv', '')  # Extract base name\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            # Read the entire DataFrame from the ft file\n",
    "            df = pd.read_csv(file_path)\n",
    "            if not df.empty:\n",
    "                dataframes_ft[base_name] = df\n",
    "        # Check if file matches the non-ft pattern\n",
    "        else:  # Identify \"non-ft\" files\n",
    "            base_name = file.replace('.csv', '')  # Extract base name\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            # Read the entire DataFrame from the non-ft file\n",
    "            df = pd.read_csv(file_path)\n",
    "            if not df.empty:\n",
    "                dataframes_non_ft[base_name] = df\n",
    "\n",
    "    # Initialize a list to store the differences DataFrames\n",
    "    list_differences = []\n",
    "\n",
    "    # Compute the differences for each matching pair\n",
    "    for base_name in dataframes_ft:\n",
    "        if base_name in dataframes_non_ft:\n",
    "            df_ft = dataframes_ft[base_name]\n",
    "            df_non_ft = dataframes_non_ft[base_name]\n",
    "\n",
    "            # Align DataFrames on both axes (rows and columns)\n",
    "            df_ft_aligned, df_non_ft_aligned = df_ft.align(df_non_ft, join='outer', axis=None, fill_value=0)\n",
    "\n",
    "            # Convert boolean columns to integers\n",
    "            for df in [df_ft_aligned, df_non_ft_aligned]:\n",
    "                bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "                df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "            # Convert all columns to numeric, coercing errors to NaN\n",
    "            df_ft_numeric = df_ft_aligned.apply(pd.to_numeric, errors='coerce')\n",
    "            df_non_ft_numeric = df_non_ft_aligned.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Fill NaN values with 0 (optional, depending on how you want to handle missing values)\n",
    "            df_ft_numeric = df_ft_numeric.fillna(0)\n",
    "            df_non_ft_numeric = df_non_ft_numeric.fillna(0)\n",
    "\n",
    "            # Compute the difference between the ft and non-ft DataFrames\n",
    "            df_diff = df_ft_numeric - df_non_ft_numeric\n",
    "\n",
    "            # Add a column to identify the pair\n",
    "            df_diff['base_name'] = base_name\n",
    "            df_diff['layer_id'] = df_ft_numeric['layer_id']\n",
    "\n",
    "            # Optional: Reset index to ensure a proper stacking\n",
    "            df_diff.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Append to the list\n",
    "            list_differences.append(df_diff)\n",
    "\n",
    "    # Concatenate all the difference DataFrames\n",
    "    if list_differences:\n",
    "        df_all_differences = pd.concat(list_differences, ignore_index=True)\n",
    "    else:\n",
    "        df_all_differences = pd.DataFrame()  # Return empty DataFrame if no differences found\n",
    "\n",
    "    return df_all_differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path_dom = 'domainnet/ww-df'\n",
    "la_dom = delta_merge_layers_(df_path_dom)\n",
    "\n",
    "la_dom = la_dom[['layer_id', 'alpha',  'entropy', 'log_norm', 'log_spectral_norm', 'base_name']]\n",
    "la_dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_d_dom = la_dom.drop(la_dom[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']][(la_dom[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']] == 0).all(axis=1)].index)\n",
    "\n",
    "la_dif_dom = compute_pairwise_differences(la_d_dom)\n",
    "la_dif_dom['category'] = la_dif_dom['base_name'].map(categorize_index)\n",
    "\n",
    "\n",
    "la_avg_dom = la_dif_dom.drop(['base_name'], axis=1).groupby(['layer_id', 'category'], as_index=False).mean()\n",
    "la_avg_dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_dom.loc[la_avg_dom['layer_id'] == 343, 'layer_id'] = 235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg_dom.groupby('category').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_all = (la_avg_cf10.iloc[:, 2:] + la_avg_cf100.iloc[:, 2:] + la_avg_car.iloc[:, 2:] + la_avg_dom.iloc[:, 2:])/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_all['layer_id'] = la_avg_cf10['layer_id']\n",
    "la_all['category'] = la_avg_cf10['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_all.iloc[:, [0, 1, 2, 3, 5]].groupby('category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means = la_all.iloc[:, [0, 1, 2, 3, 5]].groupby('category').mean()\n",
    "group_means_dict = group_means.to_dict(orient='list')\n",
    "group_means_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "data = {'alpha_diff': [0.07224881190014353,\n",
    "  0.08123956139115088,\n",
    "  0.019839655821132066],\n",
    " 'entropy_diff': [1.505595603814941e-05,\n",
    "  1.313548446581723e-05,\n",
    "  3.005355047169503e-06],\n",
    " 'log_norm_diff': [-5.7894856513136994e-06,\n",
    "  -3.315263957927679e-05,\n",
    "  -0.008005103718949726],\n",
    " 'log_spectral_norm_diff': [-0.0004998588777363196,\n",
    "  -0.00042169980104127226,\n",
    "  -0.008851174659530765]}\n",
    "df = pd.DataFrame(data, index=['div', 'dp', 'wd'])\n",
    "\n",
    "# Set up subplots: 1 row, 5 columns\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4), sharey=False)\n",
    "\n",
    "# Plot each metric separately\n",
    "for i, col in enumerate(df.columns):\n",
    "    ax = axes[i]\n",
    "    colors = ['darkblue' if val < 0 else 'skyblue' for val in df[col]]\n",
    "    df[col].plot(kind='bar', ax=ax, color=colors, edgecolor='black')\n",
    "    ax.set_title(col, fontsize=12)\n",
    "    ax.set_xticks(range(len(df.index)))\n",
    "    ax.set_xticklabels(df.index, rotation=45, fontsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()  \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last layer \n",
    "la_all[la_all['layer_id']==235].iloc[:,:-2].to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame\n",
    "data = {'alpha_diff': [4.151516333761567, 4.627669975169038, 2.2683777934609335],\n",
    " 'entropy_diff': [2.7384831152787997e-05,\n",
    "  6.778142394284897e-05,\n",
    "  1.5237653998167084e-05],\n",
    " 'log_norm_diff': [-0.0026347047471573684,\n",
    "  -0.002359189500555317,\n",
    "  -0.0036596441562315126],\n",
    " 'log_spectral_norm_diff': [-0.0008062987978322042,\n",
    "  -0.0035965202221269043,\n",
    "  -0.004208156624767036]}\n",
    "\n",
    "df = pd.DataFrame(data, index=['div', 'dp', 'wd'])\n",
    "\n",
    "# Set up subplots: 1 row, 5 columns\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4), sharey=False)\n",
    "\n",
    "# Plot each metric separately\n",
    "for i, col in enumerate(df.columns):\n",
    "    ax = axes[i]\n",
    "    colors = ['darkblue' if val < 0 else 'skyblue' for val in df[col]]\n",
    "    df[col].plot(kind='bar', ax=ax, color=colors, edgecolor='black')\n",
    "    ax.set_title(col, fontsize=12)\n",
    "    ax.set_xticks(range(len(df.index)))\n",
    "    ax.set_xticklabels(df.index, rotation=45, fontsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.tight_layout()  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['alpha_diff', 'entropy_diff', 'log_norm_diff', 'log_spectral_norm_diff']\n",
    "\n",
    "# Pivot the data to have categories as columns\n",
    "pivot_df = la_all.pivot(index='layer_id', columns='category', values=variables)\n",
    "\n",
    "# Compute Pearson correlation between categories for each variable\n",
    "for var in variables:\n",
    "    corr_matrix = pivot_df[var].corr(method='pearson')\n",
    "    print(f'Pearson Correlation for {var}:\\n{corr_matrix}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scipy.stats import f_oneway, ttest_ind\n",
    "\n",
    "categories = ['div', 'dp', 'wd']\n",
    "\n",
    "for var in variables:\n",
    "    print(f'Variable: {var}')\n",
    "    # Create a dictionary to hold series data for each category\n",
    "    series_dict = {}\n",
    "    for cat in categories:\n",
    "        series = pivot_df[var][cat].dropna().values\n",
    "        series_dict[cat] = series\n",
    "    \n",
    "    # ANOVA\n",
    "    f_stat, p_value = f_oneway(*[series_dict[cat] for cat in categories])\n",
    "    print(f'ANOVA: F-statistic={f_stat:.4f}, p-value={p_value:.4f}')\n",
    "    \n",
    "    # Pairwise t-tests\n",
    "    for cat1, cat2 in itertools.combinations(categories, 2):\n",
    "        t_stat, p_value = ttest_ind(series_dict[cat1], series_dict[cat2])\n",
    "        print(f't-test between {cat1} and {cat2}: t-statistic={t_stat:.4f}, p-value={p_value:.4f}')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "raw_text = \"\"\"Variable: alpha_diff\n",
    "ANOVA: F-statistic=0.2424, p-value=0.7850\n",
    "t-test between div and dp: t-statistic=-0.0839, p-value=0.9333\n",
    "t-test between div and wd: t-statistic=0.6083, p-value=0.5442\n",
    "t-test between dp and wd: t-statistic=0.6743, p-value=0.5015\n",
    "--------------------------------------------------\n",
    "Variable: entropy_diff\n",
    "ANOVA: F-statistic=0.1575, p-value=0.8544\n",
    "t-test between div and dp: t-statistic=0.3028, p-value=0.7626\n",
    "t-test between div and wd: t-statistic=0.4324, p-value=0.6662\n",
    "t-test between dp and wd: t-statistic=0.3628, p-value=0.7174\n",
    "--------------------------------------------------\n",
    "Variable: log_norm_diff\n",
    "ANOVA: F-statistic=23.8089, p-value=0.0000\n",
    "t-test between div and dp: t-statistic=0.4111, p-value=0.6818\n",
    "t-test between div and wd: t-statistic=4.8896, p-value=0.0000\n",
    "t-test between dp and wd: t-statistic=4.8733, p-value=0.0000\n",
    "--------------------------------------------------\n",
    "Variable: log_spectral_norm_diff\n",
    "ANOVA: F-statistic=27.0700, p-value=0.0000\n",
    "t-test between div and dp: t-statistic=-0.2538, p-value=0.8001\n",
    "t-test between div and wd: t-statistic=5.2031, p-value=0.0000\n",
    "t-test between dp and wd: t-statistic=5.2990, p-value=0.0000\n",
    "--------------------------------------------------\"\"\"  \n",
    "\n",
    "# Split by each \"Variable:\"\n",
    "sections = [s.strip() for s in raw_text.strip().split(\"Variable:\") if s.strip()]\n",
    "\n",
    "titles = []\n",
    "\n",
    "for section in sections:\n",
    "    lines = section.splitlines()\n",
    "    var_name = lines[0].strip()\n",
    "    \n",
    "    # Extract ANOVA values\n",
    "    anova_match = re.search(r\"F-statistic=([-\\d.]+), p-value=([-\\d.]+)\", section)\n",
    "    f_val = float(anova_match.group(1))\n",
    "    p_val = float(anova_match.group(2))\n",
    "    p_str = f\"p<0.001\" if p_val == 0 else f\"p={p_val:.2f}\"\n",
    "\n",
    "    # Extract all t-tests\n",
    "    t_lines = re.findall(r\"t-test between (\\w+) and (\\w+): t-statistic=([-\\d.]+), p-value=([-\\d.]+)\", section)\n",
    "    \n",
    "    t_strs = []\n",
    "    for a, b, t_stat, p_val in t_lines:\n",
    "        t_val = float(t_stat)\n",
    "        p_val = float(p_val)\n",
    "        p_fmt = \"p<0.001\" if p_val == 0 else f\"p={p_val:.2f}\"\n",
    "        t_strs.append(f\"t({a}-{b}): t={t_val:.2f}, {p_fmt}\")\n",
    "    \n",
    "    title = f'{var_name} | ANOVA: F={f_val:.2f}, {p_str} | ' + ' | '.join(t_strs)\n",
    "    titles.append(title)\n",
    "\n",
    "# Print all titles\n",
    "for t in titles:\n",
    "    print(f'title = (\\n    \"{t}\"\\n)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "# Main plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=la_all,\n",
    "    x='layer_id',\n",
    "    y='alpha_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    s=100,\n",
    "    alpha=0.8,\n",
    "    palette='Set2',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Plot formatting\n",
    "ax.set_xlabel('Layer Index', fontsize=14)\n",
    "ax.set_ylabel('Alpha', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax.grid(True)\n",
    "\n",
    "# Legend\n",
    "ax.legend(title='Category', loc='upper left', fontsize=12, title_fontsize=12)\n",
    "\n",
    "# ✅ Use absolute size + custom bottom-middle anchor\n",
    "axins = inset_axes(\n",
    "    ax,\n",
    "    width=4, height=2,  # inches\n",
    "    bbox_to_anchor=(0.25, 0.5, 0.5, 0.5),  # (x0, y0, width, height) in axes coords\n",
    "    bbox_transform=ax.transAxes,\n",
    "    loc='lower left'\n",
    ")\n",
    "\n",
    "# Zoomed-in scatterplot\n",
    "sns.scatterplot(\n",
    "    data=la_all,\n",
    "    x='layer_id',\n",
    "    y='alpha_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    s=70,\n",
    "    alpha=0.8,\n",
    "    palette='Set2',\n",
    "    ax=axins,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "title = (\n",
    "    \"ANOVA: F=0.24, p=0.79 | t(div-dp): t=-0.08, p=0.93 | t(div-wd): t=0.61, p=0.54 | t(dp-wd): t=0.67, p=0.50\"\n",
    ")\n",
    "plt.suptitle(title, fontsize=12)\n",
    "\n",
    "\n",
    "# Zoom-in limits and line\n",
    "axins.set_ylim(-0.08, 0.08)\n",
    "axins.set_xlim(la_all['layer_id'].min()-5, la_all['layer_id'].max()+5)\n",
    "axins.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axins.set_xticklabels([])\n",
    "axins.set_yticklabels([])\n",
    "axins.set_xlabel('')\n",
    "axins.set_ylabel('')\n",
    "\n",
    "# Optional: mark_inset (comment if visually confusing at bottom)\n",
    "mark_inset(ax, axins, loc1=1, loc2=2, fc=\"none\", ec=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=la_all,\n",
    "    x='layer_id',\n",
    "    y='entropy_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    s=100,\n",
    "    alpha=0.8,\n",
    "    palette='Set2',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Plot formatting\n",
    "ax.set_xlabel('Layer Index', fontsize=14)\n",
    "ax.set_ylabel('Entropy', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax.grid(True)\n",
    "\n",
    "# Legend\n",
    "ax.legend(title='Category', loc='lower left', fontsize=12, title_fontsize=12)\n",
    "\n",
    "# ✅ Use absolute size + custom bottom-middle anchor\n",
    "axins = inset_axes(\n",
    "    ax,\n",
    "    width=4, height=2,  # inches\n",
    "    bbox_to_anchor=(0.25, 0.01, 0.5, 0.5),  # (x0, y0, width, height) in axes coords\n",
    "    bbox_transform=ax.transAxes,\n",
    "    loc='upper left'\n",
    ")\n",
    "\n",
    "# Zoomed-in scatterplot\n",
    "sns.scatterplot(\n",
    "    data=la_all,\n",
    "    x='layer_id',\n",
    "    y='entropy_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    s=70,\n",
    "    alpha=0.8,\n",
    "    palette='Set2',\n",
    "    ax=axins,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "title = (\n",
    "    \"ANOVA: F=0.16, p=0.85 | t(div-dp): t=0.30, p=0.76 | t(div-wd): t=0.43, p=0.67 | t(dp-wd): t=0.36, p=0.72\"\n",
    ")\n",
    "plt.suptitle(title, fontsize=12)\n",
    "\n",
    "# Zoom-in limits and line\n",
    "axins.set_ylim(-0.0001, 0.0001)\n",
    "axins.set_xlim(la_all['layer_id'].min()-5, la_all['layer_id'].max()+5)\n",
    "axins.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axins.set_xticklabels([])\n",
    "axins.set_yticklabels([])\n",
    "axins.set_xlabel('')\n",
    "axins.set_ylabel('')\n",
    "\n",
    "# Optional: mark_inset (comment if visually confusing at bottom)\n",
    "mark_inset(ax, axins, loc1=1, loc2=2, fc=\"none\", ec=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Main line plot\n",
    "sns.lineplot(\n",
    "    data=la_all,\n",
    "    x='layer_id',\n",
    "    y='log_norm_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    palette='Set2',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Plot formatting\n",
    "ax.set_xlabel('Layer Index', fontsize=14)\n",
    "ax.set_ylabel('Log Frobenius Norm', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax.grid(True)\n",
    "ax.legend(title='Category', loc='lower left', fontsize=12, title_fontsize=12)\n",
    "\n",
    "# Inset axis for zoom-in\n",
    "axins = inset_axes(\n",
    "    ax,\n",
    "    width=4, height=2,\n",
    "    bbox_to_anchor=(0.25, 0.15, 0.3, 0.3),\n",
    "    bbox_transform=ax.transAxes,\n",
    "    loc='upper left'\n",
    ")\n",
    "\n",
    "# Zoomed-in line plot\n",
    "sns.lineplot(\n",
    "    data=la_all,\n",
    "    x='layer_id',\n",
    "    y='log_norm_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    palette='Set2',\n",
    "    ax=axins,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Zoom-in limits and formatting\n",
    "axins.set_ylim(-0.0001, 0.0002)\n",
    "axins.set_xlim(la_all['layer_id'].min() - 3, la_all['layer_id'].max() + 3)\n",
    "axins.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axins.set_xticklabels([])\n",
    "axins.set_yticklabels([])\n",
    "axins.set_xlabel('')\n",
    "axins.set_ylabel('')\n",
    "\n",
    "# Mark zoomed region on main plot\n",
    "mark_inset(ax, axins, loc1=1, loc2=2, fc=\"none\", ec=\"gray\")\n",
    "\n",
    "# Title and layout\n",
    "title = (\n",
    "    \"ANOVA: F=23.81, p<0.001 | t(div-dp): t=0.41, p=0.68 | t(div-wd): t=4.89, p<0.001 | t(dp-wd): t=4.87, p<0.001\"\n",
    ")\n",
    "plt.suptitle(title, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data=la_all,\n",
    "    x='layer_id',\n",
    "    y='log_spectral_norm_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    palette='Set2',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Plot formatting\n",
    "ax.set_xlabel('Layer Index', fontsize=14)\n",
    "ax.set_ylabel('Log Spectral Norm', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax.grid(True)\n",
    "\n",
    "# Legend\n",
    "ax.legend(title='Category', loc='lower left', fontsize=12, title_fontsize=12)\n",
    "\n",
    "# ✅ Use absolute size + custom bottom-middle anchor\n",
    "axins = inset_axes(\n",
    "    ax,\n",
    "    width=4, height=2,  # inches\n",
    "    bbox_to_anchor=(0.25, 0.15, 0.3, 0.3), # (x0, y0, width, height) in axes coords\n",
    "    bbox_transform=ax.transAxes,\n",
    "    loc='upper left'\n",
    ")\n",
    "\n",
    "# Zoomed-in scatterplot\n",
    "sns.lineplot(\n",
    "    data=la_all,\n",
    "    x='layer_id',\n",
    "    y='log_spectral_norm_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    palette='Set2',\n",
    "    ax=axins,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "title = (\n",
    "    \"ANOVA: F=27.07, p<0.001 | t(div-dp): t=-0.25, p=0.80 | t(div-wd): t=5.20, p<0.001 | t(dp-wd): t=5.30, p<0.001\"\n",
    ")\n",
    "plt.suptitle(title, fontsize=12)\n",
    "\n",
    "# Zoom-in limits and line\n",
    "axins.set_ylim(-0.003, 0.002)\n",
    "axins.set_xlim(la_all['layer_id'].min()-5, la_all['layer_id'].max()+5)\n",
    "axins.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axins.set_xticklabels([])\n",
    "axins.set_yticklabels([])\n",
    "axins.set_xlabel('')\n",
    "axins.set_ylabel('')\n",
    "\n",
    "# Optional: mark_inset (comment if visually confusing at bottom)\n",
    "mark_inset(ax, axins, loc1=1, loc2=2, fc=\"none\", ec=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diversity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
