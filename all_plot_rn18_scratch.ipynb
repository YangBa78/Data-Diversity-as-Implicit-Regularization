{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = \"train_from_scratch_10_cf10/ww-df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_merge_layers(folder_path):\n",
    "    # Initialize dictionaries to store DataFrames for ft and non-ft files\n",
    "    dataframes_ft = {}\n",
    "    dataframes_non_ft = {}\n",
    "\n",
    "    # List all CSV files in the folder\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    # Loop through each file and categorize it as 'ft' or 'non-ft'\n",
    "    for file in files:\n",
    "        # Check if file matches the ft pattern\n",
    "        if file.startswith('ft_'):  # Identify \"ft\" files\n",
    "            base_name = file.replace('ft_', '').replace('.csv', '')  # Extract base name\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            # Read the entire DataFrame from the ft file\n",
    "            df = pd.read_csv(file_path)\n",
    "            if not df.empty:\n",
    "                dataframes_ft[base_name] = df\n",
    "        # Check if file matches the non-ft pattern\n",
    "        else:  # Identify \"non-ft\" files\n",
    "            base_name = file.replace('.csv', '')  # Extract base name\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            # Read the entire DataFrame from the non-ft file\n",
    "            df = pd.read_csv(file_path)\n",
    "            if not df.empty:\n",
    "                dataframes_non_ft[base_name] = df\n",
    "\n",
    "    # Initialize a list to store the differences DataFrames\n",
    "    list_differences = []\n",
    "\n",
    "    # Compute the differences for each matching pair\n",
    "    for base_name in dataframes_ft:\n",
    "        if base_name in dataframes_non_ft:\n",
    "            df_ft = dataframes_ft[base_name]\n",
    "            df_non_ft = dataframes_non_ft[base_name]\n",
    "\n",
    "            # Align DataFrames on both axes (rows and columns)\n",
    "            df_ft_aligned, df_non_ft_aligned = df_ft.align(df_non_ft, join='outer', axis=None, fill_value=0)\n",
    "\n",
    "            # Convert boolean columns to integers\n",
    "            for df in [df_ft_aligned, df_non_ft_aligned]:\n",
    "                bool_cols = df.select_dtypes(include=['bool']).columns\n",
    "                df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "            # Convert all columns to numeric, coercing errors to NaN\n",
    "            df_ft_numeric = df_ft_aligned.apply(pd.to_numeric, errors='coerce')\n",
    "            df_non_ft_numeric = df_non_ft_aligned.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Fill NaN values with 0 (optional, depending on how you want to handle missing values)\n",
    "            df_ft_numeric = df_ft_numeric.fillna(0)\n",
    "            df_non_ft_numeric = df_non_ft_numeric.fillna(0)\n",
    "\n",
    "            # Compute the difference between the ft and non-ft DataFrames\n",
    "            df_diff = df_ft_numeric - df_non_ft_numeric\n",
    "\n",
    "            # Add a column to identify the pair\n",
    "            df_diff['base_name'] = base_name\n",
    "            df_diff['layer_id'] = df_ft_numeric['layer_id']\n",
    "\n",
    "            # Optional: Reset index to ensure a proper stacking\n",
    "            df_diff.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Append to the list\n",
    "            list_differences.append(df_diff)\n",
    "\n",
    "    # Concatenate all the difference DataFrames\n",
    "    if list_differences:\n",
    "        df_all_differences = pd.concat(list_differences, ignore_index=True)\n",
    "    else:\n",
    "        df_all_differences = pd.DataFrame()  # Return empty DataFrame if no differences found\n",
    "\n",
    "    return df_all_differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = delta_merge_layers(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = la[['layer_id', 'alpha',  'entropy', 'log_norm', 'log_spectral_norm', 'base_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_d = la.drop(la[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']][(la[['alpha',  'entropy', 'log_norm', 'log_spectral_norm']] == 0).all(axis=1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_differences(df):\n",
    "    \"\"\"\n",
    "    Computes pairwise differences between all categories and 'bs' based on 'base_name',\n",
    "    for matching 'layer_id's.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame containing 'base_name', 'layer_id', and numeric columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the differences with columns 'base_name', 'layer_id', and difference columns.\n",
    "    \"\"\"\n",
    "    # Identify numeric columns excluding 'layer_id'\n",
    "    numeric_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "    if 'layer_id' in numeric_cols:\n",
    "        numeric_cols.remove('layer_id')\n",
    "\n",
    "    # Separate 'bs' and other categories\n",
    "    df_bs = df[df['base_name'] == 'bs']\n",
    "    df_others = df[df['base_name'] != 'bs']\n",
    "\n",
    "    # Merge on 'layer_id'\n",
    "    df_merged = pd.merge(\n",
    "        df_others,\n",
    "        df_bs,\n",
    "        on='layer_id',\n",
    "        suffixes=('', '_bs'),\n",
    "        how='inner'  # Ensure only matching 'layer_id's are joined\n",
    "    )\n",
    "\n",
    "    # Compute differences for numeric columns\n",
    "    for col in numeric_cols:\n",
    "        df_merged[f'{col}_diff'] = df_merged[col] - df_merged[f'{col}_bs']\n",
    "\n",
    "    # Prepare the final DataFrame\n",
    "    cols_to_keep = ['base_name', 'layer_id'] + [f'{col}_diff' for col in numeric_cols]\n",
    "    df_differences = df_merged[cols_to_keep]\n",
    "\n",
    "    # Reset index and sort (optional)\n",
    "    df_differences.reset_index(drop=True, inplace=True)\n",
    "    df_differences.sort_values(by=['base_name', 'layer_id'], inplace=True)\n",
    "\n",
    "    return df_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(la_d['layer_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_dif = compute_pairwise_differences(la_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_index(index_value):\n",
    "    if 'div' in index_value:\n",
    "        return 'div'\n",
    "    elif 'dp' in index_value:\n",
    "        return 'dp'\n",
    "    elif 'wd' in index_value:\n",
    "        return 'wd'\n",
    "    else:\n",
    "        return 'bs'  # Optional: in case none of the patterns match\n",
    "\n",
    "# Apply the function to the index and create a new column\n",
    "la_dif['category'] = la_dif['base_name'].map(categorize_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg = la_dif.drop(['base_name'], axis=1).groupby(['layer_id', 'category'], as_index=False).mean()\n",
    "la_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['alpha_diff', 'entropy_diff', 'log_norm_diff', 'log_spectral_norm_diff']\n",
    "\n",
    "# Pivot the data to have categories as columns\n",
    "pivot_df = la_avg.pivot(index='layer_id', columns='category', values=variables)\n",
    "\n",
    "# Compute Pearson correlation between categories for each variable\n",
    "for var in variables:\n",
    "    corr_matrix = pivot_df[var].corr(method='pearson')\n",
    "    print(f'Pearson Correlation for {var}:\\n{corr_matrix}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scipy.stats import f_oneway, ttest_ind\n",
    "\n",
    "categories = ['div', 'dp', 'wd']\n",
    "\n",
    "for var in variables:\n",
    "    print(f'Variable: {var}')\n",
    "    # Create a dictionary to hold series data for each category\n",
    "    series_dict = {}\n",
    "    for cat in categories:\n",
    "        series = pivot_df[var][cat].dropna().values\n",
    "        series_dict[cat] = series\n",
    "    \n",
    "    # ANOVA\n",
    "    f_stat, p_value = f_oneway(*[series_dict[cat] for cat in categories])\n",
    "    print(f'ANOVA: F-statistic={f_stat:.4f}, p-value={p_value:.4f}')\n",
    "    \n",
    "    # Pairwise t-tests\n",
    "    for cat1, cat2 in itertools.combinations(categories, 2):\n",
    "        t_stat, p_value = ttest_ind(series_dict[cat1], series_dict[cat2])\n",
    "        print(f't-test between {cat1} and {cat2}: t-statistic={t_stat:.4f}, p-value={p_value:.4f}')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "raw_text = \"\"\"Variable: alpha_diff\n",
    "ANOVA: F-statistic=0.3248, p-value=0.7240\n",
    "t-test between div and dp: t-statistic=0.7501, p-value=0.4576\n",
    "t-test between div and wd: t-statistic=0.3435, p-value=0.7330\n",
    "t-test between dp and wd: t-statistic=-0.4806, p-value=0.6334\n",
    "--------------------------------------------------\n",
    "Variable: entropy_diff\n",
    "ANOVA: F-statistic=0.0441, p-value=0.9569\n",
    "t-test between div and dp: t-statistic=-0.2604, p-value=0.7959\n",
    "t-test between div and wd: t-statistic=-0.2173, p-value=0.8291\n",
    "t-test between dp and wd: t-statistic=0.0705, p-value=0.9441\n",
    "--------------------------------------------------\n",
    "Variable: log_norm_diff\n",
    "ANOVA: F-statistic=6.9424, p-value=0.0019\n",
    "t-test between div and dp: t-statistic=0.7400, p-value=0.4636\n",
    "t-test between div and wd: t-statistic=3.6617, p-value=0.0007\n",
    "t-test between dp and wd: t-statistic=2.3959, p-value=0.0214\n",
    "--------------------------------------------------\n",
    "Variable: log_spectral_norm_diff\n",
    "ANOVA: F-statistic=6.4808, p-value=0.0028\n",
    "t-test between div and dp: t-statistic=-1.1959, p-value=0.2388\n",
    "t-test between div and wd: t-statistic=3.0755, p-value=0.0038\n",
    "t-test between dp and wd: t-statistic=3.1859, p-value=0.0028\n",
    "--------------------------------------------------\"\"\"  # replace this with your actual block\n",
    "\n",
    "# Split by each \"Variable:\"\n",
    "sections = [s.strip() for s in raw_text.strip().split(\"Variable:\") if s.strip()]\n",
    "\n",
    "titles = []\n",
    "\n",
    "for section in sections:\n",
    "    lines = section.splitlines()\n",
    "    var_name = lines[0].strip()\n",
    "    \n",
    "    # Extract ANOVA values\n",
    "    anova_match = re.search(r\"F-statistic=([-\\d.]+), p-value=([-\\d.]+)\", section)\n",
    "    f_val = float(anova_match.group(1))\n",
    "    p_val = float(anova_match.group(2))\n",
    "    p_str = f\"p<0.001\" if p_val == 0 else f\"p={p_val:.2f}\"\n",
    "\n",
    "    # Extract all t-tests\n",
    "    t_lines = re.findall(r\"t-test between (\\w+) and (\\w+): t-statistic=([-\\d.]+), p-value=([-\\d.]+)\", section)\n",
    "    \n",
    "    t_strs = []\n",
    "    for a, b, t_stat, p_val in t_lines:\n",
    "        t_val = float(t_stat)\n",
    "        p_val = float(p_val)\n",
    "        p_fmt = \"p<0.001\" if p_val == 0 else f\"p={p_val:.2f}\"\n",
    "        t_strs.append(f\"t({a}-{b}): t={t_val:.2f}, {p_fmt}\")\n",
    "    \n",
    "    title = f'{var_name} | ANOVA: F={f_val:.2f}, {p_str} | ' + ' | '.join(t_strs)\n",
    "    titles.append(title)\n",
    "\n",
    "# Print all titles\n",
    "for t in titles:\n",
    "    print(f'title = (\\n    \"{t}\"\\n)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [(\n",
    "    \"alpha_diff | ANOVA: F=0.32, p=0.72 | t(div-dp): t=0.75, p=0.46 | t(div-wd): t=0.34, p=0.73 | t(dp-wd): t=-0.48, p=0.63\"\n",
    "),\n",
    " (\n",
    "    \"entropy_diff | ANOVA: F=0.04, p=0.96 | t(div-dp): t=-0.26, p=0.80 | t(div-wd): t=-0.22, p=0.83 | t(dp-wd): t=0.07, p=0.94\"\n",
    "),\n",
    "(\n",
    "    \"log_norm_diff | ANOVA: F=6.94, p=0.00 | t(div-dp): t=0.74, p=0.46 | t(div-wd): t=3.66, p=0.00 | t(dp-wd): t=2.40, p=0.02\"\n",
    "),\n",
    " (\n",
    "    \"log_spectral_norm_diff | ANOVA: F=6.48, p=0.00 | t(div-dp): t=-1.20, p=0.24 | t(div-wd): t=3.08, p=0.00 | t(dp-wd): t=3.19, p=0.00\"\n",
    "),\n",
    " (\n",
    "    \"stable_rank_diff | ANOVA: F=2.41, p=0.10 | t(div-dp): t=1.50, p=0.14 | t(div-wd): t=-0.34, p=0.73 | t(dp-wd): t=-1.71, p=0.10\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, y in enumerate(variables): \n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    # Line plot instead of scatter\n",
    "    sns.lineplot(\n",
    "        data=la_avg,\n",
    "        x='layer_id',\n",
    "        y=y, \n",
    "        hue='category',\n",
    "        style='category',\n",
    "        markers=True,\n",
    "        dashes=False,      # Optional: solid lines\n",
    "        palette='Set2',\n",
    "        linewidth=2,\n",
    "        marker='o'\n",
    "    )\n",
    "\n",
    "    title = titles[idx]\n",
    "    plt.suptitle(title, fontsize=10)\n",
    "    plt.xlabel('Layer Index', fontsize=14)\n",
    "    plt.ylabel(f'{y}', fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.legend(title='Category', loc='lower left', fontsize=12, title_fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Main line plot\n",
    "sns.lineplot(\n",
    "    data=la_avg,\n",
    "    x='layer_id',\n",
    "    y='log_norm_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    palette='Set2',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Plot formatting\n",
    "ax.set_xlabel('Layer Index', fontsize=14)\n",
    "ax.set_ylabel('Log Frobenius Norm', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax.grid(True)\n",
    "ax.legend(title='Category', loc='lower left', fontsize=12, title_fontsize=12)\n",
    "\n",
    "# Inset axis for zoom-in\n",
    "axins = inset_axes(\n",
    "    ax,\n",
    "    width=4, height=2,\n",
    "    bbox_to_anchor=(0.25, 0.15, 0.3, 0.3),\n",
    "    bbox_transform=ax.transAxes,\n",
    "    loc='upper left'\n",
    ")\n",
    "\n",
    "# Zoomed-in line plot\n",
    "sns.lineplot(\n",
    "    data=la_avg,\n",
    "    x='layer_id',\n",
    "    y='log_norm_diff',\n",
    "    hue='category',\n",
    "    style='category',\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    "    palette='Set2',\n",
    "    ax=axins,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "# Zoom-in limits and formatting\n",
    "axins.set_ylim(-0.003, 0.003)\n",
    "axins.set_xlim(la_avg['layer_id'].min() - 3, la_avg['layer_id'].max() + 3)\n",
    "axins.axhline(0, color='black', linestyle='--', linewidth=1)\n",
    "axins.set_xticklabels([])\n",
    "axins.set_yticklabels([])\n",
    "axins.set_xlabel('')\n",
    "axins.set_ylabel('')\n",
    "\n",
    "# Mark zoomed region on main plot\n",
    "mark_inset(ax, axins, loc1=1, loc2=2, fc=\"none\", ec=\"gray\")\n",
    "\n",
    "# Title and layout\n",
    "title = titles[2]\n",
    "plt.suptitle(title, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_avg.groupby('category').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means = la_avg.iloc[:, 1:].groupby('category').mean()\n",
    "group_means_dict = group_means.to_dict(orient='list')\n",
    "group_means_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'alpha_diff': [1.7344300010152094, -3.0487823380343766, -0.15919923004963601],\n",
    " 'entropy_diff': [-0.00031130536047236236,\n",
    "  -0.00023357615450165739,\n",
    "  -0.0002508877059758945],\n",
    " 'log_norm_diff': [-0.0022021383842999905,\n",
    "  -0.0070026744702300185,\n",
    "  -0.030421721483420656],\n",
    " 'log_spectral_norm_diff': [0.0016197139915868017,\n",
    "  0.0197249815072783,\n",
    "  -0.029077606719416976]\n",
    "}\n",
    "df = pd.DataFrame(data, index=['div', 'dp', 'wd'])\n",
    "\n",
    "# Set up subplots: 1 row, 5 columns\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4), sharey=False)\n",
    "\n",
    "# Plot each metric separately\n",
    "for i, col in enumerate(df.columns):\n",
    "    ax = axes[i]\n",
    "    colors = ['darkblue' if val < 0 else 'skyblue' for val in df[col]]\n",
    "    \n",
    "    df[col].plot(kind='bar', ax=ax, color=colors, edgecolor='black')\n",
    "    ax.set_title(col, fontsize=12)\n",
    "    ax.set_xticks(range(len(df.index)))\n",
    "    ax.set_xticklabels(df.index, rotation=45, fontsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CL layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_merge_classifier(folder_path):\n",
    "    # Initialize dictionaries to store last rows for 'ft' and 'non-ft' files\n",
    "    last_rows_ft = {}\n",
    "    last_rows_non_ft = {}\n",
    "\n",
    "    # List all files in the folder\n",
    "    files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "    # Loop through each file and categorize it as 'ft' or 'non-ft'\n",
    "    for file in files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if df.empty:  # Skip empty files\n",
    "            continue\n",
    "\n",
    "        last_row = df.iloc[-1].to_dict()  # Get the last row as a dictionary\n",
    "\n",
    "        if file.startswith('ft_'):  # Identify \"ft\" files\n",
    "            base_name = file.replace('ft_', '').replace('.csv', '')  # Extract base name\n",
    "            last_rows_ft[base_name] = last_row\n",
    "        else:  # Identify \"non-ft\" files\n",
    "            base_name = file.replace('.csv', '')  # Extract base name\n",
    "            last_rows_non_ft[base_name] = last_row\n",
    "\n",
    "    # Calculate the pairwise differences between matching 'ft' and 'non-ft' files\n",
    "    pairwise_differences = {}\n",
    "    for key in last_rows_ft:\n",
    "        if key in last_rows_non_ft:\n",
    "            # Convert to numeric and coerce errors to NaN\n",
    "            ft_row = pd.Series(last_rows_ft[key]).apply(pd.to_numeric, errors='coerce')\n",
    "            non_ft_row = pd.Series(last_rows_non_ft[key]).apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # Compute difference\n",
    "            difference_key = f\"ft_{key} - {key}\"\n",
    "            pairwise_differences[difference_key] = ft_row - non_ft_row\n",
    "\n",
    "    # Convert dictionary to DataFrame\n",
    "    df_pairwise_diff = pd.DataFrame.from_dict(pairwise_differences, orient='index')\n",
    "    df_pairwise_diff['prefix'] = df_pairwise_diff.index.str.split('_').str[1]  # Extract prefix\n",
    "    df_pairwise_diff['prefix'] = df_pairwise_diff['prefix'].str.split(' - ').str[0]\n",
    "    return df_pairwise_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = delta_merge_classifier(df_path)\n",
    "mapping = {\n",
    "    'bs': 'bs',\n",
    "    'divAugM': 'AugM',\n",
    "    'divAuto1': 'Auto1',\n",
    "    'divAuto2': 'Auto2',\n",
    "    'divAuto3': 'Auto3',\n",
    "    'divAuto': 'Auto',\n",
    "    'divNoize10': 'Noize10',\n",
    "    'divNoize30': 'Noize30',\n",
    "    'divNoize50': 'Noize50',\n",
    "    'divRand': 'Rand',\n",
    "    'divTrAu': 'TrAu',\n",
    "    'dp0.1': '0.1',\n",
    "    'dp0.3': '0.3',\n",
    "    'dp0.5': '0.5',\n",
    "    'dp0.7': '0.7',\n",
    "    'wd0.0001': '0.0001',\n",
    "    'wd0.0005': '0.0005',\n",
    "    'wd0.001': '0.001',\n",
    "    'wd0.005': '0.005',\n",
    "    'wd1e-05': '1e-05',\n",
    "    'wd5e-05': '5e-05'\n",
    "}\n",
    "\n",
    "\n",
    "cl['index'] = cl['prefix'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_index(index_value):\n",
    "    if 'div' in index_value:\n",
    "        return 'div'\n",
    "    elif 'dp' in index_value:\n",
    "        return 'dp'\n",
    "    elif 'wd' in index_value:\n",
    "        return 'wd'\n",
    "    else:\n",
    "        return 'bs'  # Optional: in case none of the patterns match\n",
    "\n",
    "# Apply the function to the index and create a new column\n",
    "cl['category'] = cl['prefix'].map(categorize_index)\n",
    "\n",
    "select_cols = ['layer_id', 'alpha',  'entropy', 'log_norm', 'log_spectral_norm', 'index', 'category']\n",
    "cl = cl[select_cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_row = cl[cl['category'] == 'bs'].iloc[0]  # Get the first row with category 'bs'\n",
    "\n",
    "# Filter numeric columns (excluding 'category')\n",
    "numeric_columns = cl.select_dtypes(include=['number']).columns\n",
    "\n",
    "cl_dif= cl[numeric_columns].subtract(bs_row[numeric_columns])\n",
    "\n",
    "# Optionally, you can add the 'category' column back\n",
    "cl_dif['category'] = cl['category']\n",
    "\n",
    "cl_dif = cl_dif.iloc[1:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means = cl_dif.iloc[:, 1:].groupby('category').mean()\n",
    "group_means_dict = group_means.to_dict(orient='list')\n",
    "group_means_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'alpha': [4.625905029533291, 7.31187117906497, 8.179463065481206],\n",
    " 'entropy': [-0.00011674819397605729,\n",
    "  -0.0009602434896870682,\n",
    "  0.0005752685914584924],\n",
    " 'log_norm': [-0.03473950709864819,\n",
    "  -0.13162307515528032,\n",
    "  -0.004959127951676949],\n",
    " 'log_spectral_norm': [-0.06070820164956142,\n",
    "  -0.10673380299841853,\n",
    "  -0.014208318523631214]}\n",
    "\n",
    "df = pd.DataFrame(data, index=['div', 'dp', 'wd'])\n",
    "\n",
    "# Set up subplots: 1 row, 5 columns\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 4), sharey=False)\n",
    "\n",
    "# Plot each metric separately\n",
    "for i, col in enumerate(df.columns):\n",
    "    ax = axes[i]\n",
    "    colors = ['darkblue' if val < 0 else 'skyblue' for val in df[col]]\n",
    "    \n",
    "    df[col].plot(kind='bar', ax=ax, color=colors, edgecolor='black')\n",
    "    ax.set_title(col, fontsize=12)\n",
    "    ax.set_xticks(range(len(df.index)))\n",
    "    ax.set_xticklabels(df.index, rotation=45, fontsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=9)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diversity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
