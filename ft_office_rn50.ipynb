{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from scripts.clip_rn50 import ClipFinetuner, train, CustomDataset, evaluate\n",
    "from scripts.datasets import office_home, convert_bytes_to_images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from vendi_score import image_utils\n",
    "import weightwatcher as ww\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"flwrlabs/office-home\")\n",
    "\n",
    "class_names, real_data = office_home('real')\n",
    "print(f\"Class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data_df = real_data.to_pandas()\n",
    "\n",
    "# Split the in-distribution data into training (80%), validation (10%), and testing (10%)\n",
    "train_val_df, test_df = train_test_split(\n",
    "    real_data_df, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=real_data_df['label']\n",
    ")\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df, \n",
    "    test_size=0.125, \n",
    "    random_state=42, \n",
    "    stratify=train_val_df['label']\n",
    ")\n",
    "\n",
    "from datasets import Dataset\n",
    "train_data = Dataset.from_pandas(train_df)\n",
    "val_data = Dataset.from_pandas(val_df)\n",
    "test_data = Dataset.from_pandas(test_df)\n",
    "\n",
    "print(f\"In-Distribution Training Data: {len(train_data)}\")\n",
    "print(f\"In-Distribution Validation Data: {len(val_data)}\")\n",
    "print(f\"In-Distribution Test Data: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_data['image']\n",
    "train_labels = train_data['label']\n",
    "classes = ds['train'].features['label'].names\n",
    "num_classes = len(set(classes))\n",
    "\n",
    "val_images = val_data['image']\n",
    "val_labels = val_data['label']\n",
    "\n",
    "test_images = test_data['image']\n",
    "test_labels = test_data['label']\n",
    "\n",
    "train_images = convert_bytes_to_images(train_images)\n",
    "val_images = convert_bytes_to_images(val_images)\n",
    "test_images = convert_bytes_to_images(test_images)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 for CLIP\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))  # CLIP's mean and std\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = {}\n",
    "loss = {}\n",
    "ece = {}\n",
    "\n",
    "# Create custom datasets\n",
    "train_dataset = CustomDataset(images=train_images, labels=train_labels, classes=classes, transform=transform)\n",
    "val_dataset = CustomDataset(images=val_images, labels=val_labels, classes=classes, transform=transform)\n",
    "test_dataset = CustomDataset(images=test_images, labels=test_labels, classes=classes, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "num_classes = len(set(train_labels))\n",
    "model = ClipFinetuner(num_classes=num_classes)\n",
    "\n",
    "torch.save(model.state_dict(), 'ft_rn50/model/model_bs.pth') #path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watcher = ww.WeightWatcher(model=model)\n",
    "details = watcher.analyze(mp_fit=True)\n",
    "summary = watcher.get_summary(details)\n",
    "\n",
    "df_bs = pd.DataFrame([summary])\n",
    "df_bs.to_csv('ft_rn50/ww-sum/bs_summary.csv', index=False)\n",
    "\n",
    "details.to_csv('ft_rn50/ww-df/bs.csv', index=False)\n",
    "\n",
    "learning_rate = 1e-5\n",
    "epochs = 5\n",
    "\n",
    "ft_model = train(model, train_dataloader, val_dataloader, num_epochs=epochs)\n",
    "\n",
    "test_loss, test_acc, test_ece = evaluate(ft_model, test_dataloader)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "print(f'Test ECE: {test_ece:.3f}')\n",
    "acc['bs'] = test_acc\n",
    "loss['bs'] = test_ece\n",
    "ece['bs'] = test_ece\n",
    "\n",
    "watcher_ft = ww.WeightWatcher(model=ft_model)\n",
    "details_ft = watcher_ft.analyze(mp_fit=True)\n",
    "summary_ft = watcher_ft.get_summary(details_ft)\n",
    "\n",
    "torch.save(ft_model.state_dict(), 'ft_rn50/model/ft_model_bs.pth')\n",
    "\n",
    "df_bs_ft = pd.DataFrame([summary_ft])\n",
    "df_bs_ft.to_csv('ft_rn50/ww-sum/ft_summary_bs.csv', index=False)\n",
    "\n",
    "details_ft .to_csv('ft_rn50/ww-df/ft_bs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rate = [0.1, 0.3, 0.5, 0.7]\n",
    "# Dictionaries to store models, watchers, and summaries\n",
    "model_dp = {}\n",
    "watcher_dp = {}\n",
    "details_dp = {}\n",
    "summary_dp = {}\n",
    "ft_model_dp = {}\n",
    "watcher_ft_dp = {}\n",
    "details_ft_dp = {}\n",
    "summary_ft_dp = {}\n",
    "\n",
    "\n",
    "# Dictionaries to store evaluation metrics\n",
    "test_loss_dict_dp = {}\n",
    "test_acc_dict_dp = {}\n",
    "test_ece_dict_dp = {}\n",
    "\n",
    "for i in dropout_rate:\n",
    "    # Define models and watchers\n",
    "    model_dp[i] = ClipFinetuner(num_classes=num_classes, block_dropout_rate=i, classifier_dropout_rate=i)\n",
    "    watcher_dp[i] = ww.WeightWatcher(model=model_dp[i])\n",
    "\n",
    "    # Perform analysis and get summary\n",
    "    details_dp[i] = watcher_dp[i].analyze(mp_fit=True)\n",
    "    summary_dp[i] = watcher_dp[i].get_summary(details_dp[i])\n",
    "\n",
    "    # Save model state\n",
    "    torch.save(model_dp[i].state_dict(), f'ft_rn50/model/model_dp{i}.pth')\n",
    "\n",
    "    # Save analysis results to CSV\n",
    "    details_dp[i].to_csv(f'ft_rn50/ww-df/dp{i}.csv', index=False)\n",
    "  \n",
    "    # Train the model\n",
    "    ft_model_dp[i] = train(model_dp[i], train_dataloader, val_dataloader, num_epochs=epochs)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_acc, test_ece = evaluate(ft_model_dp[i], test_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "\n",
    "    # Store metrics\n",
    "    test_loss_dict_dp[i] = test_loss\n",
    "    test_acc_dict_dp[i] = test_acc\n",
    "    test_ece_dict_dp[i] = test_ece\n",
    "\n",
    "    # Analyze fine-tuned model\n",
    "    watcher_ft_dp[i] = ww.WeightWatcher(model=ft_model_dp[i])\n",
    "    details_ft_dp[i] = watcher_ft_dp[i].analyze(mp_fit=True)\n",
    "    summary_ft_dp[i] = watcher_ft_dp[i].get_summary(details_ft_dp[i])\n",
    "\n",
    "    # Save fine-tuned model state\n",
    "    torch.save(ft_model_dp[i].state_dict(), f'ft_rn50/model/ft_model_dp{i}.pth')\n",
    "  \n",
    "    # Save fine-tuned analysis results to CSV\n",
    "    details_ft_dp[i].to_csv(f'ft_rn50/ww-df/ft_dp{i}.csv', index=False)\n",
    "  \n",
    "\n",
    "acc.update(test_acc_dict_dp)\n",
    "loss.update(test_loss_dict_dp)\n",
    "ece.update(test_ece_dict_dp)\n",
    "\n",
    "sum_dp = pd.DataFrame([summary_dp])\n",
    "sum_dp_ft = pd.DataFrame([summary_ft_dp])\n",
    "\n",
    "sum_dp.to_csv('ft_rn50/ww-sum/sum_dp.csv', index=False)\n",
    "\n",
    "sum_dp_ft.to_csv('ft_rn50/ww-sum/ft_sum_dp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "baseline_loss = test_loss\n",
    "baseline_accuracy = test_acc\n",
    "baseline_ece = test_ece\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(dropout_rate, [test_acc_dict_dp[i] for i in dropout_rate], marker='o', label='Accuracy')\n",
    "plt.axhline(y=baseline_accuracy, color='black', linestyle='--', label='Baseline Accuracy')\n",
    "plt.title('Accuracy vs Dropout Rate')\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(dropout_rate, [test_loss_dict_dp[i] for i in dropout_rate], marker='o', label='Loss')\n",
    "plt.axhline(y=baseline_loss, color='black', linestyle='--', label='Baseline Loss')\n",
    "plt.title('Loss vs Dropout Rate')\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot ECE\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(dropout_rate, [test_ece_dict_dp[i] for i in dropout_rate], marker='o', label='ECE')\n",
    "plt.axhline(y=baseline_ece, color='black', linestyle='--', label='Baseline ECE')\n",
    "plt.title('ECE vs Dropout Rate')\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.ylabel('ECE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay_values = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3]\n",
    "\n",
    "model_wd = {}\n",
    "watcher_wd = {}\n",
    "details_wd = {}\n",
    "summary_wd = {}\n",
    "ft_model_wd = {}\n",
    "watcher_ft_wd = {}\n",
    "details_ft_wd = {}\n",
    "summary_ft_wd = {}\n",
    "\n",
    "\n",
    "# Dictionaries to store evaluation metrics\n",
    "test_loss_dict_wd = {}\n",
    "test_acc_dict_wd = {}\n",
    "test_ece_dict_wd = {}\n",
    "\n",
    "for i in weight_decay_values:\n",
    "    # Define models and watchers\n",
    "    model_wd[i] = ClipFinetuner(num_classes=num_classes)\n",
    "    watcher_wd[i] = ww.WeightWatcher(model=model_wd[i])\n",
    "\n",
    "    # Perform analysis and get summary\n",
    "    details_wd[i] = watcher_wd[i].analyze(mp_fit=True)\n",
    "    summary_wd[i] = watcher_wd[i].get_summary(details_wd[i])\n",
    "\n",
    "    # Save model state\n",
    "    torch.save(model_wd[i].state_dict(), f'ft_rn50/model/model_wd{i}.pth')\n",
    "\n",
    "\n",
    "    # Save analysis results to CSV\n",
    "    details_wd[i].to_csv(f'ft_rn50/ww-df/wd{i}.csv', index=False)\n",
    "\n",
    "    # Train the model\n",
    "    ft_model_wd[i] = train(model_wd[i], train_dataloader, val_dataloader, num_epochs=epochs, weight_decay=i)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_acc, test_ece = evaluate(ft_model_wd[i], test_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "\n",
    "    # Store metrics\n",
    "    test_loss_dict_wd[i] = test_loss\n",
    "    test_acc_dict_wd[i] = test_acc\n",
    "    test_ece_dict_wd[i] = test_ece\n",
    "\n",
    "    # Analyze fine-tuned model\n",
    "    watcher_ft_wd[i] = ww.WeightWatcher(model=ft_model_wd[i])\n",
    "    details_ft_wd[i] = watcher_ft_wd[i].analyze(mp_fit=True)\n",
    "    summary_ft_wd[i] = watcher_ft_wd[i].get_summary(details_ft_wd[i])\n",
    "\n",
    "    # Save fine-tuned model state\n",
    "    torch.save(ft_model_wd[i].state_dict(), f'ft_rn50/model/ft_model_wd{i}.pth')\n",
    "\n",
    "    # Save fine-tuned analysis results to CSV\n",
    "    details_ft_wd[i].to_csv(f'ft_rn50/ww-df/ft_wd{i}.csv', index=False)\n",
    "\n",
    "acc.update(test_acc_dict_wd)\n",
    "loss.update(test_loss_dict_wd)\n",
    "ece.update(test_ece_dict_wd)\n",
    "\n",
    "sum_wd = pd.DataFrame([summary_wd])\n",
    "sum_wd_ft = pd.DataFrame([summary_ft_wd])\n",
    "\n",
    "sum_wd.to_csv('ft_rn50/ww-sum/sum_wd.csv', index=False)\n",
    "\n",
    "sum_wd_ft.to_csv('ft_rn50/ww-sum/ft_sum_wd.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot Accuracy\n",
    "\n",
    "baseline_loss = test_loss\n",
    "baseline_accuracy = test_acc\n",
    "baseline_ece = test_ece\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(weight_decay_values, [test_acc_dict_wd[i] for i in weight_decay_values], marker='o', label='Accuracy')\n",
    "plt.axhline(y=baseline_accuracy, color='black', linestyle='--', label='Baseline Accuracy')\n",
    "plt.title('Accuracy vs Dropout Rate')\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(weight_decay_values, [test_loss_dict_wd[i] for i in weight_decay_values], marker='o', label='Loss')\n",
    "plt.axhline(y=baseline_loss, color='black', linestyle='--', label='Baseline Loss')\n",
    "plt.title('Loss vs Dropout Rate')\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot ECE\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(weight_decay_values, [test_ece_dict_wd[i] for i in weight_decay_values], marker='o', label='ECE')\n",
    "plt.axhline(y=baseline_ece, color='black', linestyle='--', label='Baseline ECE')\n",
    "plt.title('ECE vs Dropout Rate')\n",
    "plt.xlabel('Dropout Rate')\n",
    "plt.ylabel('ECE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "rand = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.RandAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "augM = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AugMix(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "trAu = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.TrivialAugmentWide(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "class GaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, sigma=1.0, noise_ratio=1.0):\n",
    "        self.mean = mean\n",
    "        self.sigma = sigma\n",
    "        self.noise_ratio = noise_ratio\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL Image to Tensor\n",
    "        img = transforms.ToTensor()(img)\n",
    "\n",
    "        # Generate Gaussian noise\n",
    "        noise = torch.randn(img.size()) * self.sigma + self.mean\n",
    "\n",
    "        # Apply noise to the image\n",
    "        noisy_img = img + noise * self.noise_ratio\n",
    "\n",
    "        # Clip to maintain valid pixel range\n",
    "        noisy_img = torch.clamp(noisy_img, 0.0, 1.0)\n",
    "\n",
    "        # Convert back to PIL Image\n",
    "        return transforms.ToPILImage()(noisy_img)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"GaussianNoise(mean={self.mean}, sigma={self.sigma}, noise_ratio={self.noise_ratio})\"\n",
    "\n",
    "noise_01 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                   # Resizing images\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "noise_03 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                   # Resizing images\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "noise_05 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                     # Resizing images\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "auto1 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "auto2 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.5), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "auto3 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.ElasticTransform(alpha=40.0, sigma=6.0, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.5), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_div = {'Auto': auto,\n",
    "               'Rand': rand,\n",
    "               'AugM': augM,\n",
    "               'TrAu': trAu,\n",
    "               'Noize10': noise_01,\n",
    "               'Noize30': noise_03,\n",
    "               'Noize50': noise_05,\n",
    "               'Auto1': auto1,\n",
    "               'Auto2': auto2,\n",
    "               'Auto3': auto3\n",
    "               }\n",
    "\n",
    "# Dictionaries to store models, watchers, and summaries\n",
    "model_div = {}\n",
    "watcher_div = {}\n",
    "details_div = {}\n",
    "summary_div = {}\n",
    "ft_model_div = {}\n",
    "watcher_ft_div = {}\n",
    "details_ft_div = {}\n",
    "summary_ft_div = {}\n",
    "\n",
    "# Dictionaries to store evaluation metrics\n",
    "test_loss_dict_div = {}\n",
    "test_acc_dict_div = {}\n",
    "test_ece_dict_div = {}\n",
    "\n",
    "for k, v in dataset_div.items():\n",
    "\n",
    "    # Create custom datasets\n",
    "    train_dataset_div = CustomDataset(images=train_images, labels=train_labels, classes=classes, transform=v)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_dataloader_div = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Define models and watchers\n",
    "    model_div[k] = ClipFinetuner(num_classes=num_classes)\n",
    "    watcher_div[k] = ww.WeightWatcher(model=model_div[k])\n",
    "\n",
    "    # Perform analysis and get summary\n",
    "    details_div[k] = watcher_div[k].analyze(mp_fit=True)\n",
    "    summary_div[k] = watcher_div[k].get_summary(details_div[k])\n",
    "\n",
    "    # Save model state\n",
    "    torch.save(model_div[k].state_dict(), f'ft_rn50/model/model_div{k}.pth')\n",
    "\n",
    "    # Save analysis results to CSV\n",
    "    details_div[k].to_csv(f'ft_rn50/ww-df/div{k}.csv', index=False)\n",
    "\n",
    "    # Train the model\n",
    "    ft_model_div[k] = train(model_div[k], train_dataloader_div, val_dataloader, num_epochs=epochs)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_acc, test_ece = evaluate(ft_model_div[k], test_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "\n",
    "    # Store metrics\n",
    "    test_loss_dict_div[k] = test_loss\n",
    "    test_acc_dict_div[k] = test_acc\n",
    "    test_ece_dict_div[k] = test_ece\n",
    "\n",
    "    # Analyze fine-tuned model\n",
    "    watcher_ft_div[k] = ww.WeightWatcher(model=ft_model_div[k])\n",
    "    details_ft_div[k] = watcher_ft_div[k].analyze(mp_fit=True)\n",
    "    summary_ft_div[k] = watcher_ft_div[k].get_summary(details_ft_div[k])\n",
    "\n",
    "    # Save fine-tuned model state\n",
    "    torch.save(ft_model_div[k].state_dict(), f'ft_rn50/model/ft_model_div{k}.pth')\n",
    "\n",
    "    # Save fine-tuned analysis results to CSV\n",
    "    details_ft_div[k].to_csv(f'ft_rn50/ww-df/ft_div{k}.csv', index=False)\n",
    "\n",
    "\n",
    "acc.update(test_acc_dict_div)\n",
    "loss.update(test_loss_dict_div)\n",
    "ece.update(test_ece_dict_div)\n",
    "\n",
    "sum_div = pd.DataFrame([summary_div])\n",
    "sum_div_ft = pd.DataFrame([summary_ft_div])\n",
    "\n",
    "sum_div.to_csv('ft_rn50/ww-sum/sum_div.csv', index=False)\n",
    "\n",
    "sum_div_ft.to_csv('ft_rn50/ww-sum/ft_sum_div.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(dataset_div.keys())\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(keys, [test_acc_dict_div[k] for k in keys], marker='o', label='Accuracy')\n",
    "plt.axhline(y=baseline_accuracy, color='black', linestyle='--', label='Baseline Accuracy')\n",
    "plt.title('Accuracy vs Dataset Type')\n",
    "plt.xlabel('Dataset Type')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rotation=45)  # Rotate x labels for better readability\n",
    "plt.legend()\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(keys, [test_loss_dict_div[k] for k in keys], marker='o', label='Loss')\n",
    "plt.axhline(y=baseline_loss, color='black', linestyle='--', label='Baseline Loss')\n",
    "plt.title('Loss vs Dataset Type')\n",
    "plt.xlabel('Dataset Type')\n",
    "plt.ylabel('Loss')\n",
    "plt.xticks(rotation=45)  # Rotate x labels for better readability\n",
    "plt.legend()\n",
    "\n",
    "# Plot ECE\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(keys, [test_ece_dict_div[k] for k in keys], marker='o', label='ECE')\n",
    "plt.axhline(y=baseline_ece, color='black', linestyle='--', label='Baseline ECE')\n",
    "plt.title('ECE vs Dataset Type')\n",
    "plt.xlabel('Dataset Type')\n",
    "plt.ylabel('ECE')\n",
    "plt.xticks(rotation=45)  # Rotate x labels for better readability\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_to = pd.DataFrame([acc])\n",
    "ece_to =  pd.DataFrame([ece])\n",
    "loss_to = pd.DataFrame([loss])\n",
    "\n",
    "acc_to.to_csv('ft_rn50/acc.csv', index=False)\n",
    "print(f\"DataFrame saved to {'acc.csv'}\")\n",
    "\n",
    "ece_to.to_csv('ft_rn50/ece.csv', index=False)\n",
    "print(f\"DataFrame saved to {'ece.csv'}\")\n",
    "\n",
    "loss_to.to_csv('ft_rn50/loss.csv', index=False)\n",
    "print(f\"DataFrame saved to {'loss.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.vs import embedding_vendi_score\n",
    "from vendi_score import image_utils\n",
    "\n",
    "pixel = {}\n",
    "embedding = {}\n",
    "\n",
    "# baseline\n",
    "pxl = image_utils.pixel_vendi_score(train_images)\n",
    "emb = embedding_vendi_score(train_images, device=\"cuda\", model='RN50')\n",
    "print(f\"Pixel Vendi Score:{pxl:.4f}\")\n",
    "print(f\"Embedding Vendi Score: {emb:.4f}\")\n",
    "pixel['bs'] = pxl\n",
    "embedding['bs'] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.IMAGENET)\n",
    "])\n",
    "\n",
    "rand = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.RandAugment()\n",
    "])\n",
    "\n",
    "augM = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AugMix()\n",
    "])\n",
    "\n",
    "\n",
    "trAu = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.TrivialAugmentWide()\n",
    "])\n",
    "\n",
    "\n",
    "class GaussianNoise(object):\n",
    "    def __init__(self, mean=0.0, sigma=1.0, noise_ratio=1.0):\n",
    "        self.mean = mean\n",
    "        self.sigma = sigma\n",
    "        self.noise_ratio = noise_ratio\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL Image to Tensor\n",
    "        img = transforms.ToTensor()(img)\n",
    "\n",
    "        # Generate Gaussian noise\n",
    "        noise = torch.randn(img.size()) * self.sigma + self.mean\n",
    "\n",
    "        # Apply noise to the image\n",
    "        noisy_img = img + noise * self.noise_ratio\n",
    "\n",
    "        # Clip to maintain valid pixel range\n",
    "        noisy_img = torch.clamp(noisy_img, 0.0, 1.0)\n",
    "\n",
    "        # Convert back to PIL Image\n",
    "        return transforms.ToPILImage()(noisy_img)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"GaussianNoise(mean={self.mean}, sigma={self.sigma}, noise_ratio={self.noise_ratio})\"\n",
    "\n",
    "noise_01 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                   # Resizing images\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.1)\n",
    "])\n",
    "\n",
    "\n",
    "noise_03 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                   # Resizing images\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.3)\n",
    "])\n",
    "\n",
    "\n",
    "noise_05 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),                     # Resizing images\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.5)\n",
    "])\n",
    "\n",
    "auto1 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AutoAugment(),\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.5)\n",
    "])\n",
    "\n",
    "auto2 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AutoAugment(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.3),\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.5),\n",
    "])\n",
    "\n",
    "auto3 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.AutoAugment(),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomVerticalFlip(p=0.3),\n",
    "    transforms.ElasticTransform(alpha=40.0, sigma=6.0, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    GaussianNoise(mean=0.0, sigma=0.1, noise_ratio=0.5)\n",
    "])\n",
    "\n",
    "\n",
    "def auto_transform(image):\n",
    "    image = auto(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n",
    "\n",
    "def rand_transform(image):\n",
    "    image = rand(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n",
    "\n",
    "def augM_transform(image):\n",
    "    image = augM(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n",
    "\n",
    "def trAu_transform(image):\n",
    "    image = trAu(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n",
    "\n",
    "def noise_01_transform(image):\n",
    "    image = noise_01(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n",
    "\n",
    "def noise_03_transform(image):\n",
    "    image = noise_03(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n",
    "\n",
    "def noise_05_transform(image):\n",
    "    image = noise_05(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n",
    "\n",
    "def auto1_transform(image):\n",
    "    image = auto1(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n",
    "\n",
    "def auto2_transform(image):\n",
    "    image = auto2(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n",
    "\n",
    "def auto3_transform(image):\n",
    "    image = auto3(image)  # Apply auto3 transform (assumes this returns a PIL image)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_div = {'Auto': auto_transform,\n",
    "               'Rand': rand_transform,\n",
    "               'AugM': augM_transform,\n",
    "               'TrAu': trAu_transform,\n",
    "               'Noize10': noise_01_transform,\n",
    "               'Noize30': noise_03_transform,\n",
    "               'Noize50': noise_05_transform,\n",
    "               'Auto1': auto1_transform,\n",
    "               'Auto2': auto2_transform,\n",
    "               'Auto3': auto3_transform\n",
    "               }\n",
    "\n",
    "for k, v in dataset_div.items():\n",
    "\n",
    "    train_images_ = [v(image) for image in train_images]\n",
    "    val_images_ = [v(image) for image in val_images]\n",
    "\n",
    "    pxl = image_utils.pixel_vendi_score(train_images_)\n",
    "    emb = embedding_vendi_score(train_images_, device=\"cuda\", model='RN50')\n",
    "    print(f\"Pixel Vendi Score:{pxl:.4f}\")\n",
    "    print(f\"Embedding Vendi Score: {emb:.4f}\")\n",
    "\n",
    "    pixel[k] = pxl\n",
    "    embedding[k] = emb\n",
    "\n",
    "\n",
    "print(pixel)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_to = pd.DataFrame([pixel])\n",
    "embedding_to = pd.DataFrame([embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_to.to_csv('ft_rn50/pixel.csv', index=False)\n",
    "print(f\"DataFrame saved to {'pixel.csv'}\")\n",
    "\n",
    "embedding_to.to_csv('ft_rn50/embedding.csv', index=False)\n",
    "print(f\"DataFrame saved to {'embedding.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clipart_data = office_home('clipart')\n",
    "_, product_data = office_home('product')\n",
    "_, art_data = office_home('art')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipart_images = clipart_data ['image']\n",
    "clipart_labels = clipart_data['label']\n",
    "\n",
    "product_images = product_data['image']\n",
    "product_labels = product_data['label']\n",
    "\n",
    "art_images = art_data['image']\n",
    "art_labels = art_data['label']\n",
    "\n",
    "# clipart_images = convert_bytes_to_images(clipart_images)\n",
    "# product_images = convert_bytes_to_images(product_images)\n",
    "# art_images = convert_bytes_to_images(art_images)\n",
    "\n",
    "# Create custom datasets\n",
    "clipart_dataset = CustomDataset(images=clipart_images, labels=clipart_labels, classes=classes, transform=transform)\n",
    "product_dataset = CustomDataset(images=product_images, labels=product_labels, classes=classes, transform=transform)\n",
    "art_dataset = CustomDataset(images=art_images, labels=art_labels, classes=classes, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "clipart_dataloader = DataLoader(clipart_dataset, batch_size=32, shuffle=False)\n",
    "product_dataloader = DataLoader(product_dataset, batch_size=32, shuffle=False)\n",
    "art_dataloader = DataLoader(art_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_acc_clipart = {}\n",
    "ood_loss_clipart = {}\n",
    "ood_ece_clipart = {}\n",
    "\n",
    "ood_acc_product = {}\n",
    "ood_loss_product = {}\n",
    "ood_ece_product = {}\n",
    "\n",
    "ood_acc_art = {}\n",
    "ood_loss_art = {}\n",
    "ood_ece_art = {}\n",
    "\n",
    "test_loss, test_acc, test_ece = evaluate(ft_model, clipart_dataloader)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "print(f'Test ECE: {test_ece:.3f}')\n",
    "ood_acc_clipart['bs'] = test_acc\n",
    "ood_loss_clipart['bs'] = test_loss\n",
    "ood_ece_clipart['bs'] = test_ece\n",
    "\n",
    "\n",
    "test_loss, test_acc, test_ece = evaluate(ft_model, product_dataloader)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "print(f'Test ECE: {test_ece:.3f}')\n",
    "ood_acc_product['bs'] = test_acc\n",
    "ood_loss_product['bs'] = test_loss\n",
    "ood_ece_product['bs'] = test_ece\n",
    "\n",
    "\n",
    "test_loss, test_acc, test_ece = evaluate(ft_model, art_dataloader)\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "print(f'Test ECE: {test_ece:.3f}')\n",
    "ood_acc_art['bs'] = test_acc\n",
    "ood_loss_art['bs'] = test_loss\n",
    "ood_ece_art['bs'] = test_ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model_dp.items():\n",
    "    print(f\"Model: {k}\")\n",
    "    test_loss, test_acc, test_ece = evaluate(v, clipart_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "    ood_acc_clipart[k] = test_acc\n",
    "    ood_loss_clipart[k] = test_loss\n",
    "    ood_ece_clipart[k] = test_ece\n",
    "\n",
    "\n",
    "    test_loss, test_acc, test_ece = evaluate(v, product_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "    ood_acc_product[k] = test_acc\n",
    "    ood_loss_product[k] = test_loss\n",
    "    ood_ece_product[k] = test_ece\n",
    "\n",
    "\n",
    "    test_loss, test_acc, test_ece = evaluate(v, art_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "    ood_acc_art[k] = test_acc\n",
    "    ood_loss_art[k] = test_loss\n",
    "    ood_ece_art[k] = test_ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model_wd.items():\n",
    "    print(f\"Model: {k}\")\n",
    "    test_loss, test_acc, test_ece = evaluate(v, clipart_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "    ood_acc_clipart[k] = test_acc\n",
    "    ood_loss_clipart[k] = test_loss\n",
    "    ood_ece_clipart[k] = test_ece\n",
    "\n",
    "\n",
    "    test_loss, test_acc, test_ece = evaluate(v, product_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "    ood_acc_product[k] = test_acc\n",
    "    ood_loss_product[k] = test_loss\n",
    "    ood_ece_product[k] = test_ece\n",
    "\n",
    "\n",
    "    test_loss, test_acc, test_ece = evaluate(v, art_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "    ood_acc_art[k] = test_acc\n",
    "    ood_loss_art[k] = test_loss\n",
    "    ood_ece_art[k] = test_ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in model_div.items():\n",
    "    print(f\"Model: {k}\")\n",
    "    test_loss, test_acc, test_ece = evaluate(v, clipart_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "    ood_acc_clipart[k] = test_acc\n",
    "    ood_loss_clipart[k] = test_loss\n",
    "    ood_ece_clipart[k] = test_ece\n",
    "\n",
    "\n",
    "    test_loss, test_acc, test_ece = evaluate(v, product_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "    ood_acc_product[k] = test_acc\n",
    "    ood_loss_product[k] = test_loss\n",
    "    ood_ece_product[k] = test_ece\n",
    "\n",
    "\n",
    "    test_loss, test_acc, test_ece = evaluate(v, art_dataloader)\n",
    "    print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}%')\n",
    "    print(f'Test ECE: {test_ece:.3f}')\n",
    "    ood_acc_art[k] = test_acc\n",
    "    ood_loss_art[k] = test_loss\n",
    "    ood_ece_art[k] = test_ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_acc_clipart_to = pd.DataFrame([ood_acc_clipart])\n",
    "\n",
    "ood_loss_clipart_to = pd.DataFrame([ood_loss_clipart])\n",
    "\n",
    "ood_ece_clipart_to = pd.DataFrame([ood_ece_clipart])\n",
    "\n",
    "ood_acc_product_to = pd.DataFrame([ood_acc_product])\n",
    "\n",
    "ood_loss_product_to = pd.DataFrame([ood_loss_product])\n",
    "\n",
    "ood_ece_product_to = pd.DataFrame([ood_ece_product])\n",
    "\n",
    "ood_acc_art_to = pd.DataFrame([ood_acc_art])\n",
    "\n",
    "ood_loss_art_to = pd.DataFrame([ood_loss_art])\n",
    "\n",
    "ood_ece_art_to = pd.DataFrame([ood_ece_art])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_acc_clipart_to.to_csv('ft_rn50/ood_acc_clipart.csv', index=False)\n",
    "\n",
    "ood_loss_clipart_to.to_csv('ft_rn50/ood_loss_clipart.csv', index=False)\n",
    "\n",
    "ood_ece_clipart_to.to_csv('ft_rn50/ood_ece_clipart.csv', index=False)\n",
    "\n",
    "ood_acc_product_to.to_csv('ft_rn50/ood_acc_product.csv', index=False)\n",
    "\n",
    "ood_loss_product_to.to_csv('ft_rn50/ood_loss_product.csv', index=False)\n",
    "\n",
    "ood_ece_product_to.to_csv('ft_rn50/ood_ece_product.csv', index=False)\n",
    "\n",
    "ood_acc_art_to.to_csv('ft_rn50/ood_acc_art.csv', index=False)\n",
    "\n",
    "ood_loss_art_to.to_csv('ft_rn50/ood_loss_art.csv', index=False)\n",
    "\n",
    "ood_ece_art_to.to_csv('ft_rn50/ood_ece_art.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diversity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
